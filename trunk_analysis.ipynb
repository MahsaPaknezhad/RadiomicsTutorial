{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# initalizing variables\n",
    "data_dir = '../data/trunk12'\n",
    "nii_dir = '../data/trunk12_nii'\n",
    "batch_size = 32\n",
    "split_ratio = 0.9\n",
    "\n",
    "# specify transformation functions to apply on each image\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# read images from the dataset directory\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "total_num = len(dataset.targets)\n",
    "train_num = int(split_ratio * total_num)\n",
    "val_num = total_num - train_num\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "p = sns.countplot(dataset.targets, palette=['#2F3C7E', '#CCCCCC'])\n",
    "p.set_xticklabels(dataset.classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the images into train and test set\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset,[train_num, val_num])\n",
    "\n",
    "# generate a dataloader for the train set\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset.dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "# generate a dataloader for the test set\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset.dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show multiple examples of images from the training set\n",
    "train_batch = next(iter(train_loader))\n",
    "\n",
    "n = 8\n",
    "plt.figure(figsize=[15,5])\n",
    "for i in range(n):\n",
    "    img = train_batch[0][i]\n",
    "    img = torch.permute(img, (1,2,0))\n",
    "    target = dataset.classes[train_batch[1][i].item()]\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(target)\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "imgs = dataset.imgs\n",
    "\n",
    "for file, label in imgs:\n",
    "    img = Image.open(file)\n",
    "    w2 = int(img.size[0]/2)\n",
    "    h2 = int(img.size[1]/2)\n",
    "    s = 128\n",
    "    img = img.crop((w2-s, h2-s, w2+s, h2+s))\n",
    "    arr = np.asarray(img)\n",
    "    empty_header = nib.Nifti1Header()\n",
    "    affine =  np.array([[1, 0, 0, 0],\n",
    "                        [0, 1, 0, 0],\n",
    "                        [0, 0, 1, 0],\n",
    "                        [0, 0, 0, 1]])\n",
    "    another_img = nib.Nifti1Image(arr, affine, empty_header)\n",
    "    #print(another_img.header.get_data_shape())\n",
    "    file = file.replace(data_dir, nii_dir)\n",
    "    file = file.replace('.JPG', '.nii.gz')\n",
    "    path = file.replace(file.split('/')[-1], \"\")\n",
    "    os.makedirs(path, exist_ok = True)\n",
    "    nib.save(another_img, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(dataset.imgs[0][0].replace(data_dir, nii_dir).replace('.JPG', '.nii.gz'))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyradiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# save a mask file\n",
    "mask = np.ones(img.shape) *255\n",
    "mask[:1, :1, :] = 0\n",
    "mask = mask.astype(np.uint8)\n",
    "mask_name = \"mask.nii.gz\"\n",
    "print(np.unique(np.asarray(mask)))\n",
    "\n",
    "empty_header = nib.Nifti1Header()\n",
    "affine =  np.array([[1, 0, 0, 0],\n",
    "                    [0, 1, 0, 0],\n",
    "                    [0, 0, 1, 0],\n",
    "                    [0, 0, 0, 1]])\n",
    "another_img = nib.Nifti1Image(mask, affine, empty_header)\n",
    "print(another_img.header.get_data_shape())\n",
    "nib.save(another_img, mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# write a csv file with location and label of each image in the train set\n",
    "pyradiomics_header = ('Image','Mask', 'Label')\n",
    "m_arr = [mask_name] * len(train_dataset.dataset.imgs)\n",
    "img_label = train_dataset.dataset.imgs.copy()\n",
    "rows = [(il[0].replace(data_dir, nii_dir).replace('.JPG', '.nii.gz'), m, 255) for m, il in zip(m_arr, img_label)]\n",
    "rows.insert(0, pyradiomics_header)\n",
    "arr = np.asarray(rows)\n",
    "np.savetxt('pyradiomics_samples.csv', arr, fmt=\"%s\", delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import radiomics\n",
    "from radiomics import featureextractor \n",
    "\n",
    "print(train_dataset.dataset.imgs[0])\n",
    "# Instantiate the extractor\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "output = extractor.execute(train_dataset.dataset.imgs[0][0].replace(data_dir, nii_dir).replace('.JPG', '.nii.gz'), mask_name, label=255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six \n",
    "# Make an array of the values\n",
    "features = np.array([])\n",
    "\n",
    "for key, value in six.iteritems(output):\n",
    "    if key.startswith(\"original_\"):\n",
    "        features = np.append ( features, output[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(features)\n",
    "plt.yscale('log')\n",
    "plt.title ( \"Features from image\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Pyradiomics on pyradiomics_sample.csv, output to pyradi.csv\n",
    "!pyradiomics -o pyradi_features.csv -f csv pyradiomics_samples.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Declare csv Filename from Pyradiomics (zscore scaled and merged)\n",
    "fname = \"pyradi_features.csv\"\n",
    "\n",
    "# Load data\n",
    "pyradi_data = pd.read_csv(fname)\n",
    "pyradi_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradi_original = pyradi_data.iloc[:,25:]\n",
    "pyradi_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "pyradi_original.apply(zscore)\n",
    "pyradi_original.dropna(axis=1, how='all')\n",
    "pyradi_original.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradi_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradi_original['target'] = train_dataset.dataset.targets\n",
    "pyradi_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradi_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = pyradi_original.corr()\n",
    "sns.heatmap(cor, annot=False, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"target\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.2]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = relevant_features.axes[0].tolist()\n",
    "\n",
    "pyradi_relevant = pyradi_original[variables]\n",
    "pyradi_relevant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define Random Forest model\n",
    "def get_RF_models():\n",
    "\tmodels = dict()\n",
    "\ti=0.8\n",
    "\tkey = 'RF'\n",
    "\tmodels[key] = RandomForestClassifier(max_samples=i, n_estimators=30)\n",
    "\treturn models\n",
    "\n",
    "# Define Support Vector Machine model\n",
    "def get_SVM_models():\n",
    "\tmodels = dict()\n",
    "\ti=0.8\n",
    "\tkey = 'SVM'\n",
    "\tmodels[key] = SVC(kernel='rbf',probability=True)\n",
    "\treturn models\n",
    "\n",
    "def evaluate_models(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# prep classification column\n",
    "y = pyradi_relevant['target']\n",
    "\n",
    "## Run RF Classifier\n",
    "RF_max_score = 0\n",
    "for i in range(1,220):\n",
    "  j = i+2\n",
    "  if j > 215:\n",
    "    j = 215\n",
    "  X = relevant_features.iloc[:,2:j]\n",
    "  pyradi_featurename = list(relevant_features.columns)[2:j]\n",
    "  models = get_RF_models()\n",
    "  # evaluate the models and store results\n",
    "  for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_models(model, X, y)\n",
    "\t  # store the results\n",
    "    #m_scores.append(mean(scores))\n",
    "    m_scores = np.mean(scores)\n",
    "    if m_scores > RF_max_score:\n",
    "\n",
    "      RF_max_score = m_scores\n",
    "      RF_max_j = j-2\n",
    "      RF_max_std = np.std(scores)\n",
    "\t  \n",
    "\t  # summarize the performance along the way\n",
    "    #print('>%s %s %.3f %.3f (%.3f)' % (name, j-2, RF_max_score, m_scores, std(scores)))\n",
    "    print('Processing n Features: %s' % (j-2))\n",
    "print('>Model:RF  Maximum Score:%.3f  StdDev:(%.3f)  No. Features Used:%s' % (RF_max_score, RF_max_std, RF_max_j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('pytorch_python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c94a65358c242537295018150d86b8335586897a61a4a52c2e4d42219a337dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
